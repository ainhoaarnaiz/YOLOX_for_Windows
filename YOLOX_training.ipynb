{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KndWvALzfoG_"
      },
      "source": [
        "## YOLOX Installation\n",
        "Some of the installations will take a while, don't worry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check your CUDA version before installing this\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpviPxKHfh59"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Megvii-BaseDetection/YOLOX -b 0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maY7_U3gLhQA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# set the target folder\n",
        "yolox_dir = \"./YOLOX\"\n",
        "os.chdir(yolox_dir)\n",
        "print(f\"‚ö†Ô∏è Changed working directory to: {os.getcwd()}\")\n",
        "\n",
        "!pip install -U pip && pip install -r requirements.txt\n",
        "!pip install -v -e .  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KslVK6hveoHw"
      },
      "outputs": [],
      "source": [
        "!pip install loguru thop ninja onnx onnxsim onnxruntime onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install protobuf==3.20.3 setuptools==59.5.0 numpy==1.21.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pycocotools-windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC3Frlnzz5eC"
      },
      "source": [
        "#### Train/Validation split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "os.chdir(root_dir)\n",
        "print(f\"‚ö†Ô∏è Changed working directory to: {root_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkp7yRJPv0_1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# fill in the path if you want to use your own data\n",
        "dataset_directory = './02.annotation_data'\n",
        "\n",
        "\n",
        "# train/validation data path\n",
        "train_directory = './train'\n",
        "validation_directory = './validation'\n",
        "\n",
        "\n",
        "# create training data storage directory\n",
        "os.makedirs(train_directory, exist_ok=True)\n",
        "print(f\"Training data directory created at: {os.path.abspath(train_directory)}\")\n",
        "# create verification data storage directory\n",
        "os.makedirs(validation_directory, exist_ok=True)\n",
        "print(f\"Validation data directory created at: {os.path.abspath(validation_directory)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJieAq9IywqQ"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# percentage of training data\n",
        "train_ratio = 0.8\n",
        "\n",
        "# get copy source file list\n",
        "annotation_list = sorted(glob.glob(dataset_directory + '/*.xml'))\n",
        "image_list = sorted(glob.glob(dataset_directory + '/*.jpg'))\n",
        "\n",
        "file_num = len(annotation_list)\n",
        "\n",
        "# shuffle\n",
        "index_list = list(range(file_num - 1))\n",
        "random.shuffle(index_list)\n",
        "\n",
        "for count, index in enumerate(tqdm(index_list, desc=\"Copying dataset\")):\n",
        "    if count < int(file_num * train_ratio):\n",
        "        # training data\n",
        "        shutil.copy2(annotation_list[index], train_directory)\n",
        "        shutil.copy2(image_list[index], train_directory)\n",
        "    else:\n",
        "        # validation data\n",
        "        shutil.copy2(annotation_list[index], validation_directory)\n",
        "        shutil.copy2(image_list[index], validation_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACKapHgx_d4Q"
      },
      "source": [
        "#### Convert Pascal VOC format to MS COCO format (optional if using custom dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKGpaUik_c9m"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Kazuhito00/convert_voc_to_coco.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3xTEz30_kYp"
      },
      "outputs": [],
      "source": [
        "!python convert_voc_to_coco/convert_voc_to_coco.py \\\n",
        "    train train/train_annotations.json \\\n",
        "    --start_image_id=0\n",
        "!python convert_voc_to_coco/convert_voc_to_coco.py \\\n",
        "    validation validation/validation_annotations.json \\\n",
        "    --start_image_id=10000000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ9ytPB90pJP"
      },
      "source": [
        "#### Training data directory preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IccyvWRpDZGL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(\"dataset/train2017\", exist_ok=True)\n",
        "os.makedirs(\"dataset/val2017\", exist_ok=True)\n",
        "os.makedirs(\"dataset/annotations\", exist_ok=True)\n",
        "\n",
        "# Copy JPG images\n",
        "train_jpgs = [f for f in os.listdir(\"train\") if f.endswith(\".jpg\")]\n",
        "for file in tqdm(train_jpgs, desc=\"Copying training images\"):\n",
        "    shutil.copy2(os.path.join(\"train\", file), \"dataset/train2017\")\n",
        "\n",
        "# Copy validation images with progress bar\n",
        "val_jpgs = [f for f in os.listdir(\"validation\") if f.endswith(\".jpg\")]\n",
        "for file in tqdm(val_jpgs, desc=\"Copying validation images\"):\n",
        "    shutil.copy2(os.path.join(\"validation\", file), \"dataset/val2017\")\n",
        "\n",
        "# Copy annotation JSON files\n",
        "shutil.copy2(\"train/train_annotations.json\", \"dataset/annotations\")\n",
        "shutil.copy2(\"validation/validation_annotations.json\", \"dataset/annotations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "src = \"dataset\"\n",
        "dst = os.path.join(\"YOLOX\", \"dataset\")\n",
        "\n",
        "shutil.move(src, dst)\n",
        "print(f\"Moved dataset folder to: {os.path.abspath(dst)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVvBXq4e2ydb"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnUirebA1a__"
      },
      "source": [
        "#### Copying Configuration\n",
        "Check and modify configuartion as desired before copying it\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/37477845/135283504-254ea817-345e-4665-828a-4c6034645ed1.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzlWZMuSPUly"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "src = os.path.join(\"03.config\", \"nano.py\")\n",
        "dst = os.path.join(\"YOLOX\", \"nano.py\")\n",
        "shutil.copy2(src, dst)\n",
        "print(f\"Copied nano.py to: {os.path.abspath(dst)}\")\n",
        "\n",
        "src = os.path.join(\"04.scripts\", \"demo.py\")\n",
        "dst = os.path.join(\"YOLOX\", \"demo.py\")\n",
        "shutil.copy2(src, dst)\n",
        "print(f\"Copied demo.py to: {os.path.abspath(dst)}\")\n",
        "\n",
        "src = os.path.join(\"04.scripts\", \"onnx_inference.py\")\n",
        "dst = os.path.join(\"YOLOX\", \"onnx_inference.py\")\n",
        "shutil.copy2(src, dst)\n",
        "print(f\"Copied onnx_inference.py to: {os.path.abspath(dst)}\")\n",
        "\n",
        "src = os.path.join(\"04.scripts\", \"classes.txt\")\n",
        "dst = os.path.join(\"YOLOX\", \"classes.txt\")\n",
        "shutil.copy2(src, dst)\n",
        "print(f\"Copied classes.txt to: {os.path.abspath(dst)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykzClTsh1ZDA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the target folder\n",
        "yolox_dir = \"./YOLOX\"\n",
        "os.chdir(yolox_dir)\n",
        "print(f\"‚ö†Ô∏è Changed working directory to: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "url = \"https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_nano.pth\"\n",
        "response = requests.get(url, verify=False)\n",
        "with open(\"yolox_nano.pth\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "print(\"Downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQGKhyNia21V"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy2(\"tools/train.py\", \"train.py\")\n",
        "print(\"Copied train.py to current directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "\n",
        "def setup_complete_vs_environment():\n",
        "    \"\"\"\n",
        "    Complete Visual Studio environment setup for PyTorch C++ extensions\n",
        "    \"\"\"\n",
        "    vs_path = r\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\"\n",
        "    \n",
        "    print(\"Setting up complete Visual Studio environment...\")\n",
        "    \n",
        "    # 1. Find Windows SDK\n",
        "    sdk_bases = [\n",
        "        r\"C:\\Program Files (x86)\\Windows Kits\\10\",\n",
        "        r\"C:\\Program Files\\Windows Kits\\10\"\n",
        "    ]\n",
        "    \n",
        "    include_paths = []\n",
        "    lib_paths = []\n",
        "    \n",
        "    for base in sdk_bases:\n",
        "        if os.path.exists(base):\n",
        "            # Find SDK versions\n",
        "            include_base = os.path.join(base, \"Include\")\n",
        "            lib_base = os.path.join(base, \"Lib\")\n",
        "            \n",
        "            if os.path.exists(include_base):\n",
        "                versions = [d for d in os.listdir(include_base) if d.startswith(\"10.\")]\n",
        "                if versions:\n",
        "                    latest_version = max(versions)\n",
        "                    sdk_include = os.path.join(include_base, latest_version)\n",
        "                    sdk_lib = os.path.join(lib_base, latest_version)\n",
        "                    \n",
        "                    # Add SDK include paths\n",
        "                    include_paths.extend([\n",
        "                        os.path.join(sdk_include, \"ucrt\"),\n",
        "                        os.path.join(sdk_include, \"um\"),\n",
        "                        os.path.join(sdk_include, \"shared\"),\n",
        "                        os.path.join(sdk_include, \"winrt\"),\n",
        "                        os.path.join(sdk_include, \"cppwinrt\"),\n",
        "                    ])\n",
        "                    \n",
        "                    # Add SDK library paths\n",
        "                    lib_paths.extend([\n",
        "                        os.path.join(sdk_lib, \"ucrt\", \"x64\"),\n",
        "                        os.path.join(sdk_lib, \"um\", \"x64\"),\n",
        "                    ])\n",
        "                    \n",
        "                    print(f\"Found Windows SDK {latest_version}\")\n",
        "                    break\n",
        "    \n",
        "    # 2. Find MSVC tools\n",
        "    vc_tools_path = os.path.join(vs_path, \"VC\", \"Tools\", \"MSVC\")\n",
        "    if os.path.exists(vc_tools_path):\n",
        "        versions = os.listdir(vc_tools_path)\n",
        "        if versions:\n",
        "            latest_version = max(versions)\n",
        "            msvc_base = os.path.join(vc_tools_path, latest_version)\n",
        "            \n",
        "            # Add MSVC include paths\n",
        "            include_paths.extend([\n",
        "                os.path.join(msvc_base, \"include\"),\n",
        "                os.path.join(msvc_base, \"atlmfc\", \"include\"),\n",
        "            ])\n",
        "            \n",
        "            # Add MSVC library paths\n",
        "            lib_paths.extend([\n",
        "                os.path.join(msvc_base, \"lib\", \"x64\"),\n",
        "                os.path.join(msvc_base, \"atlmfc\", \"lib\", \"x64\"),\n",
        "            ])\n",
        "            \n",
        "            # Add compiler to PATH\n",
        "            bin_path = os.path.join(msvc_base, \"bin\", \"Hostx64\", \"x64\")\n",
        "            current_path = os.environ.get('PATH', '')\n",
        "            os.environ['PATH'] = f\"{bin_path};{current_path}\"\n",
        "            \n",
        "            print(f\"Found MSVC {latest_version}\")\n",
        "    \n",
        "    # 3. Set environment variables\n",
        "    # Include paths\n",
        "    current_include = os.environ.get('INCLUDE', '')\n",
        "    new_include = ';'.join(include_paths + ([current_include] if current_include else []))\n",
        "    os.environ['INCLUDE'] = new_include\n",
        "    \n",
        "    # Library paths\n",
        "    current_lib = os.environ.get('LIB', '')\n",
        "    new_lib = ';'.join(lib_paths + ([current_lib] if current_lib else []))\n",
        "    os.environ['LIB'] = new_lib\n",
        "    \n",
        "    # Essential VS environment variables\n",
        "    os.environ.update({\n",
        "        'DISTUTILS_USE_SDK': '1',\n",
        "        'MSSdk': '1',\n",
        "        'VS160COMNTOOLS': f\"{vs_path}\\\\Common7\\\\Tools\\\\\",\n",
        "        'VCINSTALLDIR': f\"{vs_path}\\\\VC\\\\\",\n",
        "        'WindowsSDKDir': sdk_bases[0] + \"\\\\\" if os.path.exists(sdk_bases[0]) else \"\",\n",
        "        'PLATFORM': 'x64',\n",
        "        'PROCESSOR_ARCHITECTURE': 'AMD64',\n",
        "    })\n",
        "    \n",
        "    print(f\"Set up {len(include_paths)} include paths\")\n",
        "    print(f\"Set up {len(lib_paths)} library paths\")\n",
        "    \n",
        "    # 4. Verify key libraries exist\n",
        "    key_libs = ['kernel32.lib', 'msvcprt.lib', 'msvcrt.lib', 'oldnames.lib']\n",
        "    found_libs = {}\n",
        "    \n",
        "    for lib_name in key_libs:\n",
        "        for lib_path in lib_paths:\n",
        "            lib_file = os.path.join(lib_path, lib_name)\n",
        "            if os.path.exists(lib_file):\n",
        "                found_libs[lib_name] = lib_file\n",
        "                break\n",
        "    \n",
        "    print(f\"\\nFound libraries: {list(found_libs.keys())}\")\n",
        "    missing_libs = set(key_libs) - set(found_libs.keys())\n",
        "    if missing_libs:\n",
        "        print(f\"Missing libraries: {list(missing_libs)}\")\n",
        "        \n",
        "        # Try to find them in other locations\n",
        "        print(\"Searching for missing libraries...\")\n",
        "        for lib_name in missing_libs:\n",
        "            for lib_path in lib_paths:\n",
        "                if os.path.exists(lib_path):\n",
        "                    all_libs = [f for f in os.listdir(lib_path) if f.endswith('.lib')]\n",
        "                    similar = [lib for lib in all_libs if lib_name.split('.')[0] in lib]\n",
        "                    if similar:\n",
        "                        print(f\"  In {lib_path}: found similar {similar[:3]}\")\n",
        "    \n",
        "    return len(missing_libs) == 0\n",
        "\n",
        "def clean_torch_cache():\n",
        "    \"\"\"Clean PyTorch extension cache to force recompilation\"\"\"\n",
        "    cache_path = os.path.expanduser(\"~/.cache/torch_extensions\")\n",
        "    if os.path.exists(cache_path):\n",
        "        import shutil\n",
        "        shutil.rmtree(cache_path)\n",
        "        print(\"Cleaned PyTorch extensions cache\")\n",
        "    \n",
        "    # Also clean the specific cache location\n",
        "    local_cache = r\"C:\\Users\\aarnaizl\\AppData\\Local\\torch_extensions\"\n",
        "    if os.path.exists(local_cache):\n",
        "        import shutil\n",
        "        shutil.rmtree(local_cache)\n",
        "        print(\"Cleaned local PyTorch extensions cache\")\n",
        "\n",
        "# Run the setup\n",
        "print(\"=== Setting up Visual Studio Environment ===\")\n",
        "success = setup_complete_vs_environment()\n",
        "\n",
        "if success:\n",
        "    print(\"\\n‚úÖ Environment setup complete!\")\n",
        "    print(\"üóëÔ∏è Cleaning PyTorch cache for fresh compilation...\")\n",
        "    clean_torch_cache()\n",
        "    print(\"\\nüöÄ Ready to run training with fast_cocoeval!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Some libraries are missing. You may need to:\")\n",
        "    print(\"Check Visual Studio Build Tools is installed with the required modules (see README.md)\")\n",
        "    \n",
        "print(\"\\nYou can now run your training command.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZDXBpaY22lN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "command = [\n",
        "    \"python\", \"train.py\",\n",
        "    \"-f\", \"nano.py\",\n",
        "    \"-d\", \"1\",\n",
        "    \"-b\", \"8\",\n",
        "    \"--fp16\",\n",
        "    \"-o\",\n",
        "    \"-c\", \"yolox_nano.pth\"\n",
        "]\n",
        "\n",
        "process = subprocess.Popen(\n",
        "    command, \n",
        "    stdout=subprocess.PIPE, \n",
        "    stderr=subprocess.STDOUT, \n",
        "    text=True,\n",
        "    encoding='utf-8',\n",
        "    errors='replace',\n",
        "    env=os.environ  # Pass the modified environment\n",
        ")\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmlvTpsheyQm"
      },
      "source": [
        "## Inference Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69XkFyYwfu-L"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy2(\"tools/demo.py\", \"demo.py\")\n",
        "print(\"Copied demo.py to current directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3g0ZRUwMP8k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "TEST_IMAGE_PATH = \"../01.image/000050.jpg\"\n",
        "MODEL_PATH = \"YOLOX_outputs/nano/best_ckpt.pth\"\n",
        "\n",
        "command = [\n",
        "    \"python\", \"demo.py\", \"image\",\n",
        "    \"-f\", \"nano.py\",\n",
        "    \"-c\", MODEL_PATH,\n",
        "    \"--path\", TEST_IMAGE_PATH,\n",
        "    \"--conf\", \"0.25\",\n",
        "    \"--nms\", \"0.45\",\n",
        "    \"--tsize\", \"640\",\n",
        "    \"--save_result\",\n",
        "    \"--device\", \"gpu\"\n",
        "]\n",
        "\n",
        "process = subprocess.Popen(\n",
        "    command, \n",
        "    stdout=subprocess.PIPE, \n",
        "    stderr=subprocess.STDOUT, \n",
        "    text=True,\n",
        "    encoding='utf-8',\n",
        "    errors='replace',\n",
        "    env=os.environ  # Pass the modified environment\n",
        ")\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT2WBgo7jAvR"
      },
      "source": [
        "## Export ONNX Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlmKqY6RfykM"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy2(\"tools/export_onnx.py\", \"export_onnx.py\")\n",
        "print(\"Copied export_onnx.py to current directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHpT0bQBhHzt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "command = [\n",
        "    \"python\", \"export_onnx.py\",\n",
        "    \"--output-name\", \"yolox_nano.onnx\",\n",
        "    \"-n\", \"yolox-nano\",\n",
        "    \"-f\", \"nano.py\",\n",
        "    \"-c\", MODEL_PATH\n",
        "]\n",
        "\n",
        "process = subprocess.Popen(\n",
        "    command, \n",
        "    stdout=subprocess.PIPE, \n",
        "    stderr=subprocess.STDOUT, \n",
        "    text=True,\n",
        "    encoding='utf-8',\n",
        "    errors='replace',\n",
        "    env=os.environ  # Pass the modified environment\n",
        ")\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYea1i3YgZE_"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "\n",
        "# shutil.copy2(\"demo/ONNXRuntime/onnx_inference.py\", \"onnx_inference.py\")\n",
        "# print(\"Copied onnx_inference.py to current directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q501MZh_jkIv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "command = [\n",
        "    \"python\",  \"-u\", \"onnx_inference.py\",\n",
        "    \"-m\", \"yolox_nano.onnx\",\n",
        "    \"-i\", TEST_IMAGE_PATH,\n",
        "    \"-o\", \"./\",\n",
        "    \"-s\", \"0.3\",\n",
        "    \"--input_shape\", \"416,416\",\n",
        "]\n",
        "\n",
        "process = subprocess.Popen(\n",
        "    command, \n",
        "    stdout=subprocess.PIPE, \n",
        "    stderr=subprocess.STDOUT, \n",
        "    text=True,\n",
        "    encoding='utf-8',\n",
        "    errors='replace',\n",
        "    env=os.environ  # Pass the modified environment\n",
        ")\n",
        "\n",
        "for line in process.stdout:\n",
        "    print(line, end=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwcQysS_j_yp"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "OUTPUT_IMAGE_PATH = \"000050.jpg\" \n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOX_Colaboratory_Training_Sample.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "yolox_colab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
